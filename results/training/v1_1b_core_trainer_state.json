{
  "best_global_step": 3500,
  "best_metric": 1.177869200706482,
  "best_model_checkpoint": "/scratch/s3219631/msc_project/msc2025/scripts/training/trained_models/checkpoint-3500",
  "epoch": 8.852026390197926,
  "eval_steps": 100,
  "global_step": 4700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0471253534401508,
      "grad_norm": 1.1558488607406616,
      "learning_rate": 5.6470588235294125e-06,
      "loss": 1.7116,
      "step": 25
    },
    {
      "epoch": 0.0942507068803016,
      "grad_norm": 2.8923122882843018,
      "learning_rate": 1.1529411764705883e-05,
      "loss": 1.6097,
      "step": 50
    },
    {
      "epoch": 0.1413760603204524,
      "grad_norm": 0.6549545526504517,
      "learning_rate": 1.7411764705882353e-05,
      "loss": 1.5184,
      "step": 75
    },
    {
      "epoch": 0.1885014137606032,
      "grad_norm": 0.6825948357582092,
      "learning_rate": 2.3294117647058824e-05,
      "loss": 1.4757,
      "step": 100
    },
    {
      "epoch": 0.1885014137606032,
      "eval_loss": 1.396910309791565,
      "eval_runtime": 55.6541,
      "eval_samples_per_second": 13.925,
      "eval_steps_per_second": 13.925,
      "step": 100
    },
    {
      "epoch": 0.235626767200754,
      "grad_norm": 0.50877445936203,
      "learning_rate": 2.9176470588235294e-05,
      "loss": 1.4212,
      "step": 125
    },
    {
      "epoch": 0.2827521206409048,
      "grad_norm": 0.43004298210144043,
      "learning_rate": 3.505882352941177e-05,
      "loss": 1.3525,
      "step": 150
    },
    {
      "epoch": 0.3298774740810556,
      "grad_norm": 0.5003700852394104,
      "learning_rate": 4.094117647058824e-05,
      "loss": 1.3364,
      "step": 175
    },
    {
      "epoch": 0.3770028275212064,
      "grad_norm": 0.4310705363750458,
      "learning_rate": 4.682352941176471e-05,
      "loss": 1.3055,
      "step": 200
    },
    {
      "epoch": 0.3770028275212064,
      "eval_loss": 1.2721765041351318,
      "eval_runtime": 54.059,
      "eval_samples_per_second": 14.336,
      "eval_steps_per_second": 14.336,
      "step": 200
    },
    {
      "epoch": 0.42412818096135724,
      "grad_norm": 0.4539005160331726,
      "learning_rate": 5.2705882352941184e-05,
      "loss": 1.2611,
      "step": 225
    },
    {
      "epoch": 0.471253534401508,
      "grad_norm": 0.4215579032897949,
      "learning_rate": 5.8588235294117654e-05,
      "loss": 1.2739,
      "step": 250
    },
    {
      "epoch": 0.5183788878416589,
      "grad_norm": 0.40665698051452637,
      "learning_rate": 6.447058823529412e-05,
      "loss": 1.2771,
      "step": 275
    },
    {
      "epoch": 0.5655042412818096,
      "grad_norm": 0.4345906376838684,
      "learning_rate": 7.035294117647059e-05,
      "loss": 1.2365,
      "step": 300
    },
    {
      "epoch": 0.5655042412818096,
      "eval_loss": 1.2349853515625,
      "eval_runtime": 54.0323,
      "eval_samples_per_second": 14.343,
      "eval_steps_per_second": 14.343,
      "step": 300
    },
    {
      "epoch": 0.6126295947219604,
      "grad_norm": 0.435833215713501,
      "learning_rate": 7.623529411764706e-05,
      "loss": 1.2281,
      "step": 325
    },
    {
      "epoch": 0.6597549481621112,
      "grad_norm": 0.4417922794818878,
      "learning_rate": 8.211764705882353e-05,
      "loss": 1.2601,
      "step": 350
    },
    {
      "epoch": 0.706880301602262,
      "grad_norm": 0.4781270921230316,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.2317,
      "step": 375
    },
    {
      "epoch": 0.7540056550424128,
      "grad_norm": 0.48106324672698975,
      "learning_rate": 9.388235294117648e-05,
      "loss": 1.25,
      "step": 400
    },
    {
      "epoch": 0.7540056550424128,
      "eval_loss": 1.2168163061141968,
      "eval_runtime": 53.9883,
      "eval_samples_per_second": 14.355,
      "eval_steps_per_second": 14.355,
      "step": 400
    },
    {
      "epoch": 0.8011310084825636,
      "grad_norm": 0.6423960328102112,
      "learning_rate": 9.976470588235295e-05,
      "loss": 1.2397,
      "step": 425
    },
    {
      "epoch": 0.8482563619227145,
      "grad_norm": 0.4871419370174408,
      "learning_rate": 9.950870010235415e-05,
      "loss": 1.2268,
      "step": 450
    },
    {
      "epoch": 0.8953817153628653,
      "grad_norm": 0.46844151616096497,
      "learning_rate": 9.899692937563972e-05,
      "loss": 1.2051,
      "step": 475
    },
    {
      "epoch": 0.942507068803016,
      "grad_norm": 0.543791651725769,
      "learning_rate": 9.848515864892529e-05,
      "loss": 1.2173,
      "step": 500
    },
    {
      "epoch": 0.942507068803016,
      "eval_loss": 1.2062523365020752,
      "eval_runtime": 54.0295,
      "eval_samples_per_second": 14.344,
      "eval_steps_per_second": 14.344,
      "step": 500
    },
    {
      "epoch": 0.9896324222431668,
      "grad_norm": 0.5030279159545898,
      "learning_rate": 9.797338792221085e-05,
      "loss": 1.1719,
      "step": 525
    },
    {
      "epoch": 1.0358152686145146,
      "grad_norm": 0.5168133974075317,
      "learning_rate": 9.746161719549642e-05,
      "loss": 1.2051,
      "step": 550
    },
    {
      "epoch": 1.0829406220546653,
      "grad_norm": 0.6932950019836426,
      "learning_rate": 9.694984646878199e-05,
      "loss": 1.1663,
      "step": 575
    },
    {
      "epoch": 1.1300659754948161,
      "grad_norm": 0.443515419960022,
      "learning_rate": 9.643807574206755e-05,
      "loss": 1.1945,
      "step": 600
    },
    {
      "epoch": 1.1300659754948161,
      "eval_loss": 1.1989134550094604,
      "eval_runtime": 54.0597,
      "eval_samples_per_second": 14.336,
      "eval_steps_per_second": 14.336,
      "step": 600
    },
    {
      "epoch": 1.177191328934967,
      "grad_norm": 0.5603684782981873,
      "learning_rate": 9.592630501535312e-05,
      "loss": 1.2042,
      "step": 625
    },
    {
      "epoch": 1.2243166823751177,
      "grad_norm": 0.5042791962623596,
      "learning_rate": 9.541453428863869e-05,
      "loss": 1.219,
      "step": 650
    },
    {
      "epoch": 1.2714420358152685,
      "grad_norm": 0.6139836311340332,
      "learning_rate": 9.490276356192425e-05,
      "loss": 1.2276,
      "step": 675
    },
    {
      "epoch": 1.3185673892554195,
      "grad_norm": 0.44859522581100464,
      "learning_rate": 9.439099283520983e-05,
      "loss": 1.1498,
      "step": 700
    },
    {
      "epoch": 1.3185673892554195,
      "eval_loss": 1.194416880607605,
      "eval_runtime": 54.1694,
      "eval_samples_per_second": 14.307,
      "eval_steps_per_second": 14.307,
      "step": 700
    },
    {
      "epoch": 1.3656927426955703,
      "grad_norm": 0.5362960696220398,
      "learning_rate": 9.38792221084954e-05,
      "loss": 1.1656,
      "step": 725
    },
    {
      "epoch": 1.412818096135721,
      "grad_norm": 0.505124032497406,
      "learning_rate": 9.336745138178097e-05,
      "loss": 1.1824,
      "step": 750
    },
    {
      "epoch": 1.4599434495758719,
      "grad_norm": 0.4424632787704468,
      "learning_rate": 9.285568065506653e-05,
      "loss": 1.1435,
      "step": 775
    },
    {
      "epoch": 1.5070688030160226,
      "grad_norm": 0.5042617321014404,
      "learning_rate": 9.23439099283521e-05,
      "loss": 1.1754,
      "step": 800
    },
    {
      "epoch": 1.5070688030160226,
      "eval_loss": 1.190928339958191,
      "eval_runtime": 53.9908,
      "eval_samples_per_second": 14.354,
      "eval_steps_per_second": 14.354,
      "step": 800
    },
    {
      "epoch": 1.5541941564561734,
      "grad_norm": 0.5146741271018982,
      "learning_rate": 9.183213920163767e-05,
      "loss": 1.1328,
      "step": 825
    },
    {
      "epoch": 1.6013195098963242,
      "grad_norm": 0.45092839002609253,
      "learning_rate": 9.132036847492324e-05,
      "loss": 1.1341,
      "step": 850
    },
    {
      "epoch": 1.648444863336475,
      "grad_norm": 0.4644491970539093,
      "learning_rate": 9.08085977482088e-05,
      "loss": 1.1626,
      "step": 875
    },
    {
      "epoch": 1.6955702167766258,
      "grad_norm": 0.5027207732200623,
      "learning_rate": 9.029682702149438e-05,
      "loss": 1.1732,
      "step": 900
    },
    {
      "epoch": 1.6955702167766258,
      "eval_loss": 1.1884933710098267,
      "eval_runtime": 54.0556,
      "eval_samples_per_second": 14.337,
      "eval_steps_per_second": 14.337,
      "step": 900
    },
    {
      "epoch": 1.7426955702167768,
      "grad_norm": 0.5807116627693176,
      "learning_rate": 8.978505629477995e-05,
      "loss": 1.1861,
      "step": 925
    },
    {
      "epoch": 1.7898209236569276,
      "grad_norm": 0.44770294427871704,
      "learning_rate": 8.927328556806552e-05,
      "loss": 1.1298,
      "step": 950
    },
    {
      "epoch": 1.8369462770970784,
      "grad_norm": 0.49416831135749817,
      "learning_rate": 8.876151484135108e-05,
      "loss": 1.1324,
      "step": 975
    },
    {
      "epoch": 1.8840716305372291,
      "grad_norm": 0.546223521232605,
      "learning_rate": 8.824974411463665e-05,
      "loss": 1.15,
      "step": 1000
    },
    {
      "epoch": 1.8840716305372291,
      "eval_loss": 1.184979796409607,
      "eval_runtime": 54.0119,
      "eval_samples_per_second": 14.349,
      "eval_steps_per_second": 14.349,
      "step": 1000
    },
    {
      "epoch": 1.93119698397738,
      "grad_norm": 0.5514788031578064,
      "learning_rate": 8.773797338792222e-05,
      "loss": 1.1483,
      "step": 1025
    },
    {
      "epoch": 1.9783223374175307,
      "grad_norm": 0.5225675106048584,
      "learning_rate": 8.722620266120778e-05,
      "loss": 1.1466,
      "step": 1050
    },
    {
      "epoch": 2.0245051837888783,
      "grad_norm": 0.5915103554725647,
      "learning_rate": 8.671443193449335e-05,
      "loss": 1.118,
      "step": 1075
    },
    {
      "epoch": 2.071630537229029,
      "grad_norm": 0.4678775668144226,
      "learning_rate": 8.620266120777892e-05,
      "loss": 1.1238,
      "step": 1100
    },
    {
      "epoch": 2.071630537229029,
      "eval_loss": 1.1849735975265503,
      "eval_runtime": 53.8807,
      "eval_samples_per_second": 14.384,
      "eval_steps_per_second": 14.384,
      "step": 1100
    },
    {
      "epoch": 2.11875589066918,
      "grad_norm": 0.47750911116600037,
      "learning_rate": 8.569089048106448e-05,
      "loss": 1.1024,
      "step": 1125
    },
    {
      "epoch": 2.1658812441093307,
      "grad_norm": 0.48771628737449646,
      "learning_rate": 8.517911975435005e-05,
      "loss": 1.1591,
      "step": 1150
    },
    {
      "epoch": 2.2130065975494815,
      "grad_norm": 0.5026200413703918,
      "learning_rate": 8.466734902763562e-05,
      "loss": 1.1664,
      "step": 1175
    },
    {
      "epoch": 2.2601319509896323,
      "grad_norm": 0.5644398331642151,
      "learning_rate": 8.415557830092118e-05,
      "loss": 1.156,
      "step": 1200
    },
    {
      "epoch": 2.2601319509896323,
      "eval_loss": 1.1837629079818726,
      "eval_runtime": 53.9883,
      "eval_samples_per_second": 14.355,
      "eval_steps_per_second": 14.355,
      "step": 1200
    },
    {
      "epoch": 2.307257304429783,
      "grad_norm": 0.5187199711799622,
      "learning_rate": 8.364380757420675e-05,
      "loss": 1.1772,
      "step": 1225
    },
    {
      "epoch": 2.354382657869934,
      "grad_norm": 0.5275084376335144,
      "learning_rate": 8.313203684749232e-05,
      "loss": 1.1352,
      "step": 1250
    },
    {
      "epoch": 2.401508011310085,
      "grad_norm": 0.6119967699050903,
      "learning_rate": 8.26202661207779e-05,
      "loss": 1.0812,
      "step": 1275
    },
    {
      "epoch": 2.4486333647502354,
      "grad_norm": 0.49909502267837524,
      "learning_rate": 8.210849539406347e-05,
      "loss": 1.1167,
      "step": 1300
    },
    {
      "epoch": 2.4486333647502354,
      "eval_loss": 1.1832002401351929,
      "eval_runtime": 53.858,
      "eval_samples_per_second": 14.39,
      "eval_steps_per_second": 14.39,
      "step": 1300
    },
    {
      "epoch": 2.4957587181903866,
      "grad_norm": 0.513582170009613,
      "learning_rate": 8.159672466734903e-05,
      "loss": 1.1653,
      "step": 1325
    },
    {
      "epoch": 2.542884071630537,
      "grad_norm": 0.5644514560699463,
      "learning_rate": 8.10849539406346e-05,
      "loss": 1.1396,
      "step": 1350
    },
    {
      "epoch": 2.590009425070688,
      "grad_norm": 0.6071364283561707,
      "learning_rate": 8.057318321392017e-05,
      "loss": 1.1627,
      "step": 1375
    },
    {
      "epoch": 2.637134778510839,
      "grad_norm": 0.5056179761886597,
      "learning_rate": 8.006141248720573e-05,
      "loss": 1.1106,
      "step": 1400
    },
    {
      "epoch": 2.637134778510839,
      "eval_loss": 1.1807652711868286,
      "eval_runtime": 54.7422,
      "eval_samples_per_second": 14.157,
      "eval_steps_per_second": 14.157,
      "step": 1400
    },
    {
      "epoch": 2.68426013195099,
      "grad_norm": 0.567554771900177,
      "learning_rate": 7.95496417604913e-05,
      "loss": 1.0847,
      "step": 1425
    },
    {
      "epoch": 2.7313854853911406,
      "grad_norm": 0.49671074748039246,
      "learning_rate": 7.903787103377687e-05,
      "loss": 1.1104,
      "step": 1450
    },
    {
      "epoch": 2.7785108388312914,
      "grad_norm": 0.5357786417007446,
      "learning_rate": 7.852610030706245e-05,
      "loss": 1.0818,
      "step": 1475
    },
    {
      "epoch": 2.825636192271442,
      "grad_norm": 0.6077888607978821,
      "learning_rate": 7.801432958034801e-05,
      "loss": 1.118,
      "step": 1500
    },
    {
      "epoch": 2.825636192271442,
      "eval_loss": 1.1806316375732422,
      "eval_runtime": 54.8775,
      "eval_samples_per_second": 14.122,
      "eval_steps_per_second": 14.122,
      "step": 1500
    },
    {
      "epoch": 2.872761545711593,
      "grad_norm": 0.5375646352767944,
      "learning_rate": 7.750255885363358e-05,
      "loss": 1.1312,
      "step": 1525
    },
    {
      "epoch": 2.9198868991517437,
      "grad_norm": 0.5250539183616638,
      "learning_rate": 7.699078812691915e-05,
      "loss": 1.0959,
      "step": 1550
    },
    {
      "epoch": 2.9670122525918945,
      "grad_norm": 0.4667842984199524,
      "learning_rate": 7.647901740020471e-05,
      "loss": 1.0971,
      "step": 1575
    },
    {
      "epoch": 3.013195098963242,
      "grad_norm": 0.5361042618751526,
      "learning_rate": 7.596724667349028e-05,
      "loss": 1.0843,
      "step": 1600
    },
    {
      "epoch": 3.013195098963242,
      "eval_loss": 1.1799004077911377,
      "eval_runtime": 54.0426,
      "eval_samples_per_second": 14.341,
      "eval_steps_per_second": 14.341,
      "step": 1600
    },
    {
      "epoch": 3.060320452403393,
      "grad_norm": 0.481431782245636,
      "learning_rate": 7.545547594677585e-05,
      "loss": 1.1171,
      "step": 1625
    },
    {
      "epoch": 3.1074458058435437,
      "grad_norm": 0.5732707381248474,
      "learning_rate": 7.494370522006142e-05,
      "loss": 1.142,
      "step": 1650
    },
    {
      "epoch": 3.1545711592836945,
      "grad_norm": 0.5015819072723389,
      "learning_rate": 7.443193449334698e-05,
      "loss": 1.1299,
      "step": 1675
    },
    {
      "epoch": 3.2016965127238453,
      "grad_norm": 0.5515692234039307,
      "learning_rate": 7.392016376663255e-05,
      "loss": 1.0892,
      "step": 1700
    },
    {
      "epoch": 3.2016965127238453,
      "eval_loss": 1.1816755533218384,
      "eval_runtime": 54.103,
      "eval_samples_per_second": 14.325,
      "eval_steps_per_second": 14.325,
      "step": 1700
    },
    {
      "epoch": 3.248821866163996,
      "grad_norm": 0.5401878952980042,
      "learning_rate": 7.340839303991812e-05,
      "loss": 1.1301,
      "step": 1725
    },
    {
      "epoch": 3.2959472196041473,
      "grad_norm": 0.4852125346660614,
      "learning_rate": 7.289662231320368e-05,
      "loss": 1.0832,
      "step": 1750
    },
    {
      "epoch": 3.3430725730442976,
      "grad_norm": 0.5215729475021362,
      "learning_rate": 7.238485158648925e-05,
      "loss": 1.0928,
      "step": 1775
    },
    {
      "epoch": 3.390197926484449,
      "grad_norm": 0.5175482630729675,
      "learning_rate": 7.187308085977482e-05,
      "loss": 1.1087,
      "step": 1800
    },
    {
      "epoch": 3.390197926484449,
      "eval_loss": 1.1809238195419312,
      "eval_runtime": 53.9232,
      "eval_samples_per_second": 14.372,
      "eval_steps_per_second": 14.372,
      "step": 1800
    },
    {
      "epoch": 3.4373232799245996,
      "grad_norm": 0.5268968939781189,
      "learning_rate": 7.136131013306038e-05,
      "loss": 1.08,
      "step": 1825
    },
    {
      "epoch": 3.4844486333647504,
      "grad_norm": 0.5666052103042603,
      "learning_rate": 7.084953940634595e-05,
      "loss": 1.1103,
      "step": 1850
    },
    {
      "epoch": 3.531573986804901,
      "grad_norm": 0.4641907811164856,
      "learning_rate": 7.033776867963153e-05,
      "loss": 1.0676,
      "step": 1875
    },
    {
      "epoch": 3.578699340245052,
      "grad_norm": 0.6198315024375916,
      "learning_rate": 6.98259979529171e-05,
      "loss": 1.0899,
      "step": 1900
    },
    {
      "epoch": 3.578699340245052,
      "eval_loss": 1.1805380582809448,
      "eval_runtime": 53.9603,
      "eval_samples_per_second": 14.362,
      "eval_steps_per_second": 14.362,
      "step": 1900
    },
    {
      "epoch": 3.6258246936852028,
      "grad_norm": 0.4794946014881134,
      "learning_rate": 6.931422722620266e-05,
      "loss": 1.094,
      "step": 1925
    },
    {
      "epoch": 3.6729500471253536,
      "grad_norm": 0.5101209878921509,
      "learning_rate": 6.880245649948823e-05,
      "loss": 1.066,
      "step": 1950
    },
    {
      "epoch": 3.7200754005655043,
      "grad_norm": 0.5829480886459351,
      "learning_rate": 6.82906857727738e-05,
      "loss": 1.1215,
      "step": 1975
    },
    {
      "epoch": 3.767200754005655,
      "grad_norm": 0.5501084923744202,
      "learning_rate": 6.777891504605936e-05,
      "loss": 1.0739,
      "step": 2000
    },
    {
      "epoch": 3.767200754005655,
      "eval_loss": 1.1809264421463013,
      "eval_runtime": 53.8949,
      "eval_samples_per_second": 14.38,
      "eval_steps_per_second": 14.38,
      "step": 2000
    },
    {
      "epoch": 3.814326107445806,
      "grad_norm": 0.5839720368385315,
      "learning_rate": 6.726714431934493e-05,
      "loss": 1.0632,
      "step": 2025
    },
    {
      "epoch": 3.8614514608859567,
      "grad_norm": 0.5507393479347229,
      "learning_rate": 6.675537359263051e-05,
      "loss": 1.0684,
      "step": 2050
    },
    {
      "epoch": 3.9085768143261075,
      "grad_norm": 0.6070751547813416,
      "learning_rate": 6.624360286591608e-05,
      "loss": 1.0813,
      "step": 2075
    },
    {
      "epoch": 3.9557021677662583,
      "grad_norm": 0.5163424611091614,
      "learning_rate": 6.573183213920165e-05,
      "loss": 1.0819,
      "step": 2100
    },
    {
      "epoch": 3.9557021677662583,
      "eval_loss": 1.179115891456604,
      "eval_runtime": 53.7344,
      "eval_samples_per_second": 14.423,
      "eval_steps_per_second": 14.423,
      "step": 2100
    },
    {
      "epoch": 4.001885014137606,
      "grad_norm": 0.5065926909446716,
      "learning_rate": 6.522006141248721e-05,
      "loss": 1.0865,
      "step": 2125
    },
    {
      "epoch": 4.049010367577757,
      "grad_norm": 0.5259211659431458,
      "learning_rate": 6.470829068577278e-05,
      "loss": 1.0998,
      "step": 2150
    },
    {
      "epoch": 4.096135721017908,
      "grad_norm": 0.5009984970092773,
      "learning_rate": 6.419651995905835e-05,
      "loss": 1.0354,
      "step": 2175
    },
    {
      "epoch": 4.143261074458058,
      "grad_norm": 0.5948050022125244,
      "learning_rate": 6.368474923234391e-05,
      "loss": 1.0754,
      "step": 2200
    },
    {
      "epoch": 4.143261074458058,
      "eval_loss": 1.1792569160461426,
      "eval_runtime": 53.6902,
      "eval_samples_per_second": 14.435,
      "eval_steps_per_second": 14.435,
      "step": 2200
    },
    {
      "epoch": 4.1903864278982095,
      "grad_norm": 0.5087001323699951,
      "learning_rate": 6.317297850562948e-05,
      "loss": 1.1059,
      "step": 2225
    },
    {
      "epoch": 4.23751178133836,
      "grad_norm": 0.7952375411987305,
      "learning_rate": 6.266120777891506e-05,
      "loss": 1.082,
      "step": 2250
    },
    {
      "epoch": 4.284637134778511,
      "grad_norm": 0.6551229357719421,
      "learning_rate": 6.214943705220063e-05,
      "loss": 1.1392,
      "step": 2275
    },
    {
      "epoch": 4.331762488218661,
      "grad_norm": 0.5670745372772217,
      "learning_rate": 6.163766632548618e-05,
      "loss": 1.1042,
      "step": 2300
    },
    {
      "epoch": 4.331762488218661,
      "eval_loss": 1.1791472434997559,
      "eval_runtime": 53.628,
      "eval_samples_per_second": 14.451,
      "eval_steps_per_second": 14.451,
      "step": 2300
    },
    {
      "epoch": 4.378887841658813,
      "grad_norm": 0.5875148773193359,
      "learning_rate": 6.112589559877175e-05,
      "loss": 1.0646,
      "step": 2325
    },
    {
      "epoch": 4.426013195098963,
      "grad_norm": 0.5484226942062378,
      "learning_rate": 6.061412487205732e-05,
      "loss": 1.0424,
      "step": 2350
    },
    {
      "epoch": 4.473138548539114,
      "grad_norm": 0.6659773588180542,
      "learning_rate": 6.010235414534289e-05,
      "loss": 1.0992,
      "step": 2375
    },
    {
      "epoch": 4.5202639019792645,
      "grad_norm": 0.5090245604515076,
      "learning_rate": 5.9590583418628455e-05,
      "loss": 1.0374,
      "step": 2400
    },
    {
      "epoch": 4.5202639019792645,
      "eval_loss": 1.1812856197357178,
      "eval_runtime": 53.6632,
      "eval_samples_per_second": 14.442,
      "eval_steps_per_second": 14.442,
      "step": 2400
    },
    {
      "epoch": 4.567389255419416,
      "grad_norm": 0.5856747031211853,
      "learning_rate": 5.907881269191402e-05,
      "loss": 1.0854,
      "step": 2425
    },
    {
      "epoch": 4.614514608859566,
      "grad_norm": 0.5498066544532776,
      "learning_rate": 5.8567041965199596e-05,
      "loss": 1.0871,
      "step": 2450
    },
    {
      "epoch": 4.661639962299717,
      "grad_norm": 0.657172441482544,
      "learning_rate": 5.805527123848516e-05,
      "loss": 1.0924,
      "step": 2475
    },
    {
      "epoch": 4.708765315739868,
      "grad_norm": 0.5611826181411743,
      "learning_rate": 5.754350051177073e-05,
      "loss": 1.0741,
      "step": 2500
    },
    {
      "epoch": 4.708765315739868,
      "eval_loss": 1.1790125370025635,
      "eval_runtime": 55.0249,
      "eval_samples_per_second": 14.085,
      "eval_steps_per_second": 14.085,
      "step": 2500
    },
    {
      "epoch": 4.755890669180019,
      "grad_norm": 0.6209368109703064,
      "learning_rate": 5.7031729785056296e-05,
      "loss": 1.0532,
      "step": 2525
    },
    {
      "epoch": 4.80301602262017,
      "grad_norm": 0.5300451517105103,
      "learning_rate": 5.651995905834186e-05,
      "loss": 1.0639,
      "step": 2550
    },
    {
      "epoch": 4.8501413760603205,
      "grad_norm": 0.5438839197158813,
      "learning_rate": 5.600818833162743e-05,
      "loss": 1.0523,
      "step": 2575
    },
    {
      "epoch": 4.897266729500471,
      "grad_norm": 0.5798086524009705,
      "learning_rate": 5.5496417604913e-05,
      "loss": 1.0956,
      "step": 2600
    },
    {
      "epoch": 4.897266729500471,
      "eval_loss": 1.1796406507492065,
      "eval_runtime": 55.3607,
      "eval_samples_per_second": 13.999,
      "eval_steps_per_second": 13.999,
      "step": 2600
    },
    {
      "epoch": 4.944392082940622,
      "grad_norm": 0.5539448857307434,
      "learning_rate": 5.4984646878198564e-05,
      "loss": 1.0728,
      "step": 2625
    },
    {
      "epoch": 4.991517436380773,
      "grad_norm": 0.5773442983627319,
      "learning_rate": 5.4472876151484144e-05,
      "loss": 1.078,
      "step": 2650
    },
    {
      "epoch": 5.0377002827521205,
      "grad_norm": 0.5747589468955994,
      "learning_rate": 5.396110542476971e-05,
      "loss": 1.0801,
      "step": 2675
    },
    {
      "epoch": 5.084825636192272,
      "grad_norm": 0.5735785961151123,
      "learning_rate": 5.344933469805528e-05,
      "loss": 1.0824,
      "step": 2700
    },
    {
      "epoch": 5.084825636192272,
      "eval_loss": 1.1802711486816406,
      "eval_runtime": 55.243,
      "eval_samples_per_second": 14.029,
      "eval_steps_per_second": 14.029,
      "step": 2700
    },
    {
      "epoch": 5.131950989632422,
      "grad_norm": 0.6426702737808228,
      "learning_rate": 5.2937563971340845e-05,
      "loss": 1.0293,
      "step": 2725
    },
    {
      "epoch": 5.179076343072573,
      "grad_norm": 0.5675122737884521,
      "learning_rate": 5.242579324462641e-05,
      "loss": 1.0849,
      "step": 2750
    },
    {
      "epoch": 5.226201696512724,
      "grad_norm": 0.5424527525901794,
      "learning_rate": 5.191402251791198e-05,
      "loss": 1.0251,
      "step": 2775
    },
    {
      "epoch": 5.273327049952875,
      "grad_norm": 0.598260760307312,
      "learning_rate": 5.1402251791197545e-05,
      "loss": 1.0605,
      "step": 2800
    },
    {
      "epoch": 5.273327049952875,
      "eval_loss": 1.1819796562194824,
      "eval_runtime": 54.583,
      "eval_samples_per_second": 14.199,
      "eval_steps_per_second": 14.199,
      "step": 2800
    },
    {
      "epoch": 5.320452403393025,
      "grad_norm": 0.4889277517795563,
      "learning_rate": 5.089048106448311e-05,
      "loss": 1.021,
      "step": 2825
    },
    {
      "epoch": 5.367577756833176,
      "grad_norm": 0.9024693965911865,
      "learning_rate": 5.0378710337768686e-05,
      "loss": 1.0994,
      "step": 2850
    },
    {
      "epoch": 5.414703110273327,
      "grad_norm": 0.5850369334220886,
      "learning_rate": 4.9866939611054246e-05,
      "loss": 1.0718,
      "step": 2875
    },
    {
      "epoch": 5.461828463713478,
      "grad_norm": 0.5743946433067322,
      "learning_rate": 4.935516888433982e-05,
      "loss": 1.0827,
      "step": 2900
    },
    {
      "epoch": 5.461828463713478,
      "eval_loss": 1.1811857223510742,
      "eval_runtime": 54.1895,
      "eval_samples_per_second": 14.302,
      "eval_steps_per_second": 14.302,
      "step": 2900
    },
    {
      "epoch": 5.508953817153628,
      "grad_norm": 0.5377157926559448,
      "learning_rate": 4.8843398157625386e-05,
      "loss": 1.1239,
      "step": 2925
    },
    {
      "epoch": 5.5560791705937795,
      "grad_norm": 0.5852324962615967,
      "learning_rate": 4.833162743091095e-05,
      "loss": 1.0308,
      "step": 2950
    },
    {
      "epoch": 5.60320452403393,
      "grad_norm": 0.7807661294937134,
      "learning_rate": 4.781985670419652e-05,
      "loss": 1.0432,
      "step": 2975
    },
    {
      "epoch": 5.650329877474081,
      "grad_norm": 0.526627779006958,
      "learning_rate": 4.7308085977482094e-05,
      "loss": 1.051,
      "step": 3000
    },
    {
      "epoch": 5.650329877474081,
      "eval_loss": 1.1816765069961548,
      "eval_runtime": 54.1421,
      "eval_samples_per_second": 14.314,
      "eval_steps_per_second": 14.314,
      "step": 3000
    },
    {
      "epoch": 5.6974552309142314,
      "grad_norm": 0.6454588770866394,
      "learning_rate": 4.679631525076766e-05,
      "loss": 1.0587,
      "step": 3025
    },
    {
      "epoch": 5.744580584354383,
      "grad_norm": 0.5319182872772217,
      "learning_rate": 4.628454452405323e-05,
      "loss": 1.0531,
      "step": 3050
    },
    {
      "epoch": 5.791705937794534,
      "grad_norm": 0.5300183892250061,
      "learning_rate": 4.5772773797338794e-05,
      "loss": 1.0097,
      "step": 3075
    },
    {
      "epoch": 5.838831291234684,
      "grad_norm": 0.6035199165344238,
      "learning_rate": 4.526100307062436e-05,
      "loss": 1.1064,
      "step": 3100
    },
    {
      "epoch": 5.838831291234684,
      "eval_loss": 1.1816778182983398,
      "eval_runtime": 52.7166,
      "eval_samples_per_second": 14.701,
      "eval_steps_per_second": 14.701,
      "step": 3100
    },
    {
      "epoch": 5.885956644674835,
      "grad_norm": 0.602509617805481,
      "learning_rate": 4.474923234390993e-05,
      "loss": 1.0586,
      "step": 3125
    },
    {
      "epoch": 5.933081998114986,
      "grad_norm": 0.5656200647354126,
      "learning_rate": 4.4237461617195495e-05,
      "loss": 1.0443,
      "step": 3150
    },
    {
      "epoch": 5.980207351555137,
      "grad_norm": 0.59990394115448,
      "learning_rate": 4.372569089048107e-05,
      "loss": 1.0798,
      "step": 3175
    },
    {
      "epoch": 6.026390197926484,
      "grad_norm": 0.5008190274238586,
      "learning_rate": 4.3213920163766635e-05,
      "loss": 1.0528,
      "step": 3200
    },
    {
      "epoch": 6.026390197926484,
      "eval_loss": 1.1807639598846436,
      "eval_runtime": 53.6628,
      "eval_samples_per_second": 14.442,
      "eval_steps_per_second": 14.442,
      "step": 3200
    },
    {
      "epoch": 6.0735155513666355,
      "grad_norm": 0.5759726762771606,
      "learning_rate": 4.27021494370522e-05,
      "loss": 1.0515,
      "step": 3225
    },
    {
      "epoch": 6.120640904806786,
      "grad_norm": 0.563741147518158,
      "learning_rate": 4.219037871033777e-05,
      "loss": 1.0617,
      "step": 3250
    },
    {
      "epoch": 6.167766258246937,
      "grad_norm": 1.046315312385559,
      "learning_rate": 4.167860798362334e-05,
      "loss": 1.0988,
      "step": 3275
    },
    {
      "epoch": 6.214891611687087,
      "grad_norm": 0.6825586557388306,
      "learning_rate": 4.116683725690891e-05,
      "loss": 1.0386,
      "step": 3300
    },
    {
      "epoch": 6.214891611687087,
      "eval_loss": 1.1796127557754517,
      "eval_runtime": 54.8302,
      "eval_samples_per_second": 14.135,
      "eval_steps_per_second": 14.135,
      "step": 3300
    },
    {
      "epoch": 6.262016965127239,
      "grad_norm": 0.6875731945037842,
      "learning_rate": 4.0655066530194476e-05,
      "loss": 1.0723,
      "step": 3325
    },
    {
      "epoch": 6.309142318567389,
      "grad_norm": 0.5574434995651245,
      "learning_rate": 4.014329580348004e-05,
      "loss": 1.0536,
      "step": 3350
    },
    {
      "epoch": 6.35626767200754,
      "grad_norm": 0.5686613321304321,
      "learning_rate": 3.963152507676561e-05,
      "loss": 1.0065,
      "step": 3375
    },
    {
      "epoch": 6.4033930254476905,
      "grad_norm": 0.6123506426811218,
      "learning_rate": 3.911975435005118e-05,
      "loss": 1.042,
      "step": 3400
    },
    {
      "epoch": 6.4033930254476905,
      "eval_loss": 1.1798374652862549,
      "eval_runtime": 54.9026,
      "eval_samples_per_second": 14.116,
      "eval_steps_per_second": 14.116,
      "step": 3400
    },
    {
      "epoch": 6.450518378887842,
      "grad_norm": 0.5807580947875977,
      "learning_rate": 3.8607983623336744e-05,
      "loss": 1.0724,
      "step": 3425
    },
    {
      "epoch": 6.497643732327992,
      "grad_norm": 0.6032187938690186,
      "learning_rate": 3.809621289662231e-05,
      "loss": 1.0565,
      "step": 3450
    },
    {
      "epoch": 6.544769085768143,
      "grad_norm": 0.5216261744499207,
      "learning_rate": 3.7584442169907884e-05,
      "loss": 1.058,
      "step": 3475
    },
    {
      "epoch": 6.5918944392082945,
      "grad_norm": 0.5071332454681396,
      "learning_rate": 3.707267144319345e-05,
      "loss": 1.0744,
      "step": 3500
    },
    {
      "epoch": 6.5918944392082945,
      "eval_loss": 1.177869200706482,
      "eval_runtime": 54.7421,
      "eval_samples_per_second": 14.157,
      "eval_steps_per_second": 14.157,
      "step": 3500
    },
    {
      "epoch": 6.639019792648445,
      "grad_norm": 0.5527859330177307,
      "learning_rate": 3.656090071647902e-05,
      "loss": 1.0294,
      "step": 3525
    },
    {
      "epoch": 6.686145146088595,
      "grad_norm": 0.5463290214538574,
      "learning_rate": 3.6049129989764585e-05,
      "loss": 1.1068,
      "step": 3550
    },
    {
      "epoch": 6.7332704995287465,
      "grad_norm": 0.4812444746494293,
      "learning_rate": 3.553735926305016e-05,
      "loss": 1.0514,
      "step": 3575
    },
    {
      "epoch": 6.780395852968898,
      "grad_norm": 0.5723158121109009,
      "learning_rate": 3.5025588536335725e-05,
      "loss": 1.0217,
      "step": 3600
    },
    {
      "epoch": 6.780395852968898,
      "eval_loss": 1.1801819801330566,
      "eval_runtime": 55.0325,
      "eval_samples_per_second": 14.083,
      "eval_steps_per_second": 14.083,
      "step": 3600
    },
    {
      "epoch": 6.827521206409048,
      "grad_norm": 0.5154834389686584,
      "learning_rate": 3.451381780962129e-05,
      "loss": 1.0611,
      "step": 3625
    },
    {
      "epoch": 6.874646559849199,
      "grad_norm": 0.616974949836731,
      "learning_rate": 3.400204708290686e-05,
      "loss": 1.1125,
      "step": 3650
    },
    {
      "epoch": 6.92177191328935,
      "grad_norm": 0.5765308141708374,
      "learning_rate": 3.3490276356192426e-05,
      "loss": 1.0753,
      "step": 3675
    },
    {
      "epoch": 6.968897266729501,
      "grad_norm": 0.5859551429748535,
      "learning_rate": 3.297850562947799e-05,
      "loss": 1.073,
      "step": 3700
    },
    {
      "epoch": 6.968897266729501,
      "eval_loss": 1.181572437286377,
      "eval_runtime": 54.4168,
      "eval_samples_per_second": 14.242,
      "eval_steps_per_second": 14.242,
      "step": 3700
    },
    {
      "epoch": 7.015080113100848,
      "grad_norm": 0.672024130821228,
      "learning_rate": 3.246673490276356e-05,
      "loss": 1.0105,
      "step": 3725
    },
    {
      "epoch": 7.062205466540999,
      "grad_norm": 0.5289613604545593,
      "learning_rate": 3.1954964176049127e-05,
      "loss": 1.0595,
      "step": 3750
    },
    {
      "epoch": 7.10933081998115,
      "grad_norm": 0.5750095248222351,
      "learning_rate": 3.14431934493347e-05,
      "loss": 1.0224,
      "step": 3775
    },
    {
      "epoch": 7.156456173421301,
      "grad_norm": 0.6746587753295898,
      "learning_rate": 3.093142272262027e-05,
      "loss": 1.045,
      "step": 3800
    },
    {
      "epoch": 7.156456173421301,
      "eval_loss": 1.179867148399353,
      "eval_runtime": 54.4975,
      "eval_samples_per_second": 14.221,
      "eval_steps_per_second": 14.221,
      "step": 3800
    },
    {
      "epoch": 7.203581526861451,
      "grad_norm": 0.5636529922485352,
      "learning_rate": 3.0419651995905834e-05,
      "loss": 1.0007,
      "step": 3825
    },
    {
      "epoch": 7.250706880301602,
      "grad_norm": 0.633691132068634,
      "learning_rate": 2.99078812691914e-05,
      "loss": 1.0019,
      "step": 3850
    },
    {
      "epoch": 7.297832233741753,
      "grad_norm": 0.6244432330131531,
      "learning_rate": 2.9396110542476974e-05,
      "loss": 1.0369,
      "step": 3875
    },
    {
      "epoch": 7.344957587181904,
      "grad_norm": 0.6635037660598755,
      "learning_rate": 2.888433981576254e-05,
      "loss": 1.0197,
      "step": 3900
    },
    {
      "epoch": 7.344957587181904,
      "eval_loss": 1.1826092004776,
      "eval_runtime": 54.5351,
      "eval_samples_per_second": 14.211,
      "eval_steps_per_second": 14.211,
      "step": 3900
    },
    {
      "epoch": 7.392082940622054,
      "grad_norm": 0.5600728988647461,
      "learning_rate": 2.8372569089048108e-05,
      "loss": 1.0417,
      "step": 3925
    },
    {
      "epoch": 7.4392082940622055,
      "grad_norm": 0.6234883666038513,
      "learning_rate": 2.786079836233367e-05,
      "loss": 1.0928,
      "step": 3950
    },
    {
      "epoch": 7.486333647502356,
      "grad_norm": 0.5877049565315247,
      "learning_rate": 2.7349027635619245e-05,
      "loss": 1.0735,
      "step": 3975
    },
    {
      "epoch": 7.533459000942507,
      "grad_norm": 0.5910993814468384,
      "learning_rate": 2.6837256908904812e-05,
      "loss": 1.0548,
      "step": 4000
    },
    {
      "epoch": 7.533459000942507,
      "eval_loss": 1.1809617280960083,
      "eval_runtime": 54.4926,
      "eval_samples_per_second": 14.222,
      "eval_steps_per_second": 14.222,
      "step": 4000
    },
    {
      "epoch": 7.580584354382658,
      "grad_norm": 2.001331329345703,
      "learning_rate": 2.632548618219038e-05,
      "loss": 1.0237,
      "step": 4025
    },
    {
      "epoch": 7.627709707822809,
      "grad_norm": 0.6219662427902222,
      "learning_rate": 2.5813715455475946e-05,
      "loss": 1.041,
      "step": 4050
    },
    {
      "epoch": 7.674835061262959,
      "grad_norm": 0.6297547221183777,
      "learning_rate": 2.5301944728761516e-05,
      "loss": 1.0269,
      "step": 4075
    },
    {
      "epoch": 7.72196041470311,
      "grad_norm": 0.5530669093132019,
      "learning_rate": 2.4790174002047083e-05,
      "loss": 1.0037,
      "step": 4100
    },
    {
      "epoch": 7.72196041470311,
      "eval_loss": 1.1812034845352173,
      "eval_runtime": 55.0559,
      "eval_samples_per_second": 14.077,
      "eval_steps_per_second": 14.077,
      "step": 4100
    },
    {
      "epoch": 7.7690857681432615,
      "grad_norm": 0.7730621695518494,
      "learning_rate": 2.4278403275332653e-05,
      "loss": 1.0477,
      "step": 4125
    },
    {
      "epoch": 7.816211121583412,
      "grad_norm": 0.6810910701751709,
      "learning_rate": 2.376663254861822e-05,
      "loss": 1.0749,
      "step": 4150
    },
    {
      "epoch": 7.863336475023563,
      "grad_norm": 0.5235051512718201,
      "learning_rate": 2.325486182190379e-05,
      "loss": 1.0485,
      "step": 4175
    },
    {
      "epoch": 7.910461828463713,
      "grad_norm": 0.6186785697937012,
      "learning_rate": 2.2743091095189357e-05,
      "loss": 1.0535,
      "step": 4200
    },
    {
      "epoch": 7.910461828463713,
      "eval_loss": 1.1806972026824951,
      "eval_runtime": 55.2001,
      "eval_samples_per_second": 14.04,
      "eval_steps_per_second": 14.04,
      "step": 4200
    },
    {
      "epoch": 7.957587181903865,
      "grad_norm": 0.6157176494598389,
      "learning_rate": 2.2231320368474924e-05,
      "loss": 1.0474,
      "step": 4225
    },
    {
      "epoch": 8.003770028275213,
      "grad_norm": 0.9434967041015625,
      "learning_rate": 2.171954964176049e-05,
      "loss": 1.049,
      "step": 4250
    },
    {
      "epoch": 8.050895381715362,
      "grad_norm": 0.6088296175003052,
      "learning_rate": 2.120777891504606e-05,
      "loss": 1.0285,
      "step": 4275
    },
    {
      "epoch": 8.098020735155513,
      "grad_norm": 0.6031464338302612,
      "learning_rate": 2.0696008188331628e-05,
      "loss": 1.0592,
      "step": 4300
    },
    {
      "epoch": 8.098020735155513,
      "eval_loss": 1.1806350946426392,
      "eval_runtime": 52.4348,
      "eval_samples_per_second": 14.78,
      "eval_steps_per_second": 14.78,
      "step": 4300
    },
    {
      "epoch": 8.145146088595665,
      "grad_norm": 0.5326116681098938,
      "learning_rate": 2.0184237461617198e-05,
      "loss": 1.0201,
      "step": 4325
    },
    {
      "epoch": 8.192271442035816,
      "grad_norm": 0.5749324560165405,
      "learning_rate": 1.9672466734902765e-05,
      "loss": 1.0082,
      "step": 4350
    },
    {
      "epoch": 8.239396795475965,
      "grad_norm": 0.5691666603088379,
      "learning_rate": 1.9160696008188332e-05,
      "loss": 1.0434,
      "step": 4375
    },
    {
      "epoch": 8.286522148916116,
      "grad_norm": 0.537757396697998,
      "learning_rate": 1.86489252814739e-05,
      "loss": 0.9964,
      "step": 4400
    },
    {
      "epoch": 8.286522148916116,
      "eval_loss": 1.1798248291015625,
      "eval_runtime": 52.3671,
      "eval_samples_per_second": 14.799,
      "eval_steps_per_second": 14.799,
      "step": 4400
    },
    {
      "epoch": 8.333647502356268,
      "grad_norm": 0.564650297164917,
      "learning_rate": 1.813715455475947e-05,
      "loss": 1.0589,
      "step": 4425
    },
    {
      "epoch": 8.380772855796419,
      "grad_norm": 0.6753618717193604,
      "learning_rate": 1.7625383828045036e-05,
      "loss": 1.0251,
      "step": 4450
    },
    {
      "epoch": 8.42789820923657,
      "grad_norm": 0.5638821721076965,
      "learning_rate": 1.7113613101330606e-05,
      "loss": 1.0861,
      "step": 4475
    },
    {
      "epoch": 8.47502356267672,
      "grad_norm": 0.5625887513160706,
      "learning_rate": 1.6601842374616173e-05,
      "loss": 1.0878,
      "step": 4500
    },
    {
      "epoch": 8.47502356267672,
      "eval_loss": 1.1808359622955322,
      "eval_runtime": 55.8571,
      "eval_samples_per_second": 13.875,
      "eval_steps_per_second": 13.875,
      "step": 4500
    },
    {
      "epoch": 8.52214891611687,
      "grad_norm": 0.6791058778762817,
      "learning_rate": 1.609007164790174e-05,
      "loss": 1.0436,
      "step": 4525
    },
    {
      "epoch": 8.569274269557022,
      "grad_norm": 0.6385700702667236,
      "learning_rate": 1.5578300921187307e-05,
      "loss": 1.0639,
      "step": 4550
    },
    {
      "epoch": 8.616399622997172,
      "grad_norm": 0.626251220703125,
      "learning_rate": 1.5066530194472877e-05,
      "loss": 1.0552,
      "step": 4575
    },
    {
      "epoch": 8.663524976437323,
      "grad_norm": 0.590623676776886,
      "learning_rate": 1.4554759467758444e-05,
      "loss": 1.0465,
      "step": 4600
    },
    {
      "epoch": 8.663524976437323,
      "eval_loss": 1.1821314096450806,
      "eval_runtime": 53.5469,
      "eval_samples_per_second": 14.473,
      "eval_steps_per_second": 14.473,
      "step": 4600
    },
    {
      "epoch": 8.710650329877474,
      "grad_norm": 0.59475177526474,
      "learning_rate": 1.4042988741044014e-05,
      "loss": 1.0235,
      "step": 4625
    },
    {
      "epoch": 8.757775683317625,
      "grad_norm": 0.6168351173400879,
      "learning_rate": 1.3531218014329581e-05,
      "loss": 1.0639,
      "step": 4650
    },
    {
      "epoch": 8.804901036757776,
      "grad_norm": 0.7154977917671204,
      "learning_rate": 1.301944728761515e-05,
      "loss": 1.0196,
      "step": 4675
    },
    {
      "epoch": 8.852026390197926,
      "grad_norm": 0.5974161624908447,
      "learning_rate": 1.2507676560900716e-05,
      "loss": 1.0775,
      "step": 4700
    },
    {
      "epoch": 8.852026390197926,
      "eval_loss": 1.1813328266143799,
      "eval_runtime": 52.4857,
      "eval_samples_per_second": 14.766,
      "eval_steps_per_second": 14.766,
      "step": 4700
    }
  ],
  "logging_steps": 25,
  "max_steps": 5310,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 12,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 12
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2060249580714394e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
